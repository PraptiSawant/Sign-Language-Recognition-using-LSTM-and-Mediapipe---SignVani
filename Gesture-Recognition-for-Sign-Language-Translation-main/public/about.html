<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>About</title>
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css">
    <link rel="stylesheet" href = "css/nav_bar.css">
    <link rel="stylesheet" href = "css/about.css">
    <link href="https://cdn.jsdelivr.net/npm/remixicon@2.2.0/fonts/remixicon.css" rel="stylesheet">
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Poppins&display=swap" rel="stylesheet">
    <script src="https://code.jquery.com/jquery-3.4.1.slim.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js"></script>
    <script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/all.min.css">

    
</head>
<body>
  <section id="nav-bar">
    <nav class="navbar navbar-expand-lg navbar-light ">
        <a class="navbar-brand nav-link" href="./home.html" ><img src="./assets/lie (1).png"><h1>SignVani</h1></a>
        <div class="navbar-collapse" id="navbarNav" style="">
          <ul class="navbar-nav ml-auto">
            <li class="nav-item">
              <a class="nav-link" href="./home.html"><i class="ri-home-5-line"></i></i>
                <span class="nav__name">Home</span></a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="./sample.html"><i class="ri-camera-line"></i><span class="nav__name">Webcame</span></a>
            </li>
            <li class="nav-item">
              <a class="nav-link" href="./FileUpload/FileUpload.html"><i class="ri-folder-upload-line"></i><span class="nav__name">Video Upload</span></a>
            </li>            
            <li class="nav-item">
                <a class="nav-link" href="./aboutus.html"><i class="ri-information-line"></i><span class="nav__name">About</span></a>
            </li>
          </ul>
         </div>
      </nav>
</section>


<div class="container">
    <div class="row" id="row_arrow_1">
      <div class="col-4"> 
         <div class="graph__wrapper">
        <svg id="arrow1"  viewBox="0 0 315 107" version="1.1" >
          <g  id="Page-1" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd" sketch:type="MSPage">
            <path id="Path-1" class="path" fill="none" stroke="#db5862" stroke-width="5" stroke-linejoin="round" stroke-miterlimit="10" d="M1.4,2.1c0,0,86,57,211.5,41.5s172.5-24.5,289,81"/>
      
      <path class="dashed" fill="none" stroke="white" stroke-width="8" stroke-linejoin="round" stroke-miterlimit="10" d="M1.4,2.1c0,0,86,57,211.5,41.5s172.5-24.5,289,81"/>   
            
            <polyline id="arrow1" points="0,-9 18,0 0,9 5,0" fill="#db5862">
              <animateMotion rotate="auto" begin="1s" dur="1.6s" repeatCount="1" fill="freeze">
                <mpath xlink:href="#Path-1" />
              </animateMotion>
            </polyline>
      
          </g>
        </svg>
        
      </div>
    </div>
      <div class="col-8" >    
       



 

</div>
    
  
      
    </div>
    <div class="row">
      <div class="col-4">  
    </div>
      <div class="col-8" id="main_info" >
       
        <div class="blog-slider">
          <div class="blog-slider__wrp swiper-wrapper">
            <div class="blog-slider__item swiper-slide">
              
              <div class="blog-slider__img ">
                
                <img src="assets/img3.jpg" alt="">
              </div>
              <div class="blog-slider__content">
               
                <div class="blog-slider__title">SignVani</div>
                <div class="blog-slider__text">SignVani is an innovative project that aims to bridge the communication gap between sign language users and non-sign language speakers. Using advanced computer vision techniques, it detects and translates sign language gestures into English text, allowing seamless communication. Additionally, SignVani goes a step further by translating the English text into Konkani and utilizing text-to-speech technology to deliver spoken translations in the Konkani language, making it accessible to goan audience and promoting inclusivity. </div>
               
              </div>
            </div>          
            
           
            
          </div>
         
        </div>
  

 



 

</div>
    
  
      
    </div>
    <div class="row" id="row_arrow_2">
      <div class="col-4" id="col-arrow2">
       
        <div class="graph__wrapper">
        <svg id="arrow2"  viewBox="0 0 315 107" version="1.1" >
          <g  id="Page-2" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd" sketch:type="MSPage">
            <path id="Path-2" class="path" fill="none" stroke="#db5862" stroke-width="5" stroke-linejoin="round" stroke-miterlimit="10" d="M1.5,3.1c0,0,200,4,-270.5,64.5s250.5+10.5,-100,170"/>
      
      <path class="dashed" fill="none" stroke="white" stroke-width="8" stroke-linejoin="round" stroke-miterlimit="10" d="M1.5,3.1c0,0,200,4,-270.5,64.5s250.5+10.5,-100,170"/>   
            
            <polyline id="arrow2" points="0,-9 18,0 0,9 5,0" fill="#db5862">
              <animateMotion rotate="auto" begin="1s" dur="1.6s" repeatCount="1" fill="freeze">
                <mpath xlink:href="#Path-2" />
              </animateMotion>
            </polyline>
      
          </g>
        </svg>
      </div>
      <p class="model" >Models Used to build SignVani Project</p>
    </div>
    <div class="col-8" >
      
    
       
      </div>
     
    </div>
    <div class="row">
      <div class="col-4" >
       
    </div>
    <div class="col-8" id="info">
      
      <div class="blog-slider">
        <div class="blog-slider__wrp swiper-wrapper">
          <div class="blog-slider__item swiper-slide">
            <div class="blog-slider__img ">
              
              <img src="assets/lstm.gif" alt="">
            </div>
            <div class="blog-slider__content">
              <span class="blog-slider__code">Sign to English</span>
              <div class="blog-slider__title">LSTM</div>
              <div class="blog-slider__text">LSTM networks are recurrent neural networks that may learn order dependence in sequence prediction challengesThe LSTM (Long Short-Term Memory) model is a powerful neural network architecture commonly used for sign language detection. By leveraging its ability to capture long-range dependencies and handle sequential data, the LSTM model demonstrates promising accuracy in recognizing and interpreting sign language gestures, facilitating effective communication for the deaf and hard of hearing. </div>
              <a href="https://medium.com/@mayank.bali/sign-language-detection-for-deaf-using-deep-learning-mediapipe-u-opencv-4c5151e2374c" class="blog-slider__button">SEE MORE</a>
            </div>
         </div>
       </div>
      </div>
       
      </div>
     
    </div>
    <div class="row" id="row_arrow_3">
      <div class="col-4">
          <div class="graph__wrapper">
        <svg id="arrow1"  viewBox="0 0 315 107" version="1.1" >
          <g  id="Page-1" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd" sketch:type="MSPage">
            <path id="Path-1" class="path" fill="none" stroke="#db5862" stroke-width="5" stroke-linejoin="round" stroke-miterlimit="10" d="M1.4,2.1c0,0,86,57,211.5,41.5s172.5-24.5,289,81"/>
      
      <path class="dashed" fill="none" stroke="white" stroke-width="8" stroke-linejoin="round" stroke-miterlimit="10" d="M1.4,2.1c0,0,86,57,211.5,41.5s172.5-24.5,289,81"/>   
            
            <polyline id="arrow1" points="0,-9 18,0 0,9 5,0" fill="#db5862">
              <animateMotion rotate="auto" begin="1s" dur="1.6s" repeatCount="1" fill="freeze">
                <mpath xlink:href="#Path-1" />
              </animateMotion>
            </polyline>
      
          </g>
        </svg>
        
      </div>
    </div>
      <div class="col-8" > 



 

</div>
    
  
      
    </div>
    <div class="row">
      <div class="col-4">  
    </div>
      <div class="col-8" id="info2" >
       
        <div class="blog-slider">
          <div class="blog-slider__wrp swiper-wrapper">
            <div class="blog-slider__item swiper-slide">
              <div class="blog-slider__img ">
                
                <img src="assets/encoderdecoder.gif" alt="">
              </div>
              <div class="blog-slider__content">
                <span class="blog-slider__code">konkani translation</span>
                <div class="blog-slider__title">Seq2Seq-LSTM-Model</div>
                <div class="blog-slider__text">The Seq2Seq-LSTM model is a sophisticated deep learning architecture that excels in English to Konkani text translation. By employing a sequence-to-sequence framework with LSTM layers, it captures the contextual information and linguistic patterns to generate accurate and meaningful translations, bridging the language barrier between English and Konkani with impressive fluency and precision.? </div>
                <a href="https://www.codingninjas.com/codestudio/library/encoder-decoder-models" class="blog-slider__button">READ MORE</a>
              </div>
            </div>          
            
           
            
          </div>
         
        </div>
  

 



 

</div>
    
  
      
    </div>
    <div class="row" id="row_arrow_2">
      <div class="col-4" id="col-arrow2">
        <div class="graph__wrapper">
        <svg id="arrow2"  viewBox="0 0 315 107" version="1.1" >
          <g  id="Page-2" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd" sketch:type="MSPage">
            <path id="Path-2" class="path" fill="none" stroke="#db5862" stroke-width="5" stroke-linejoin="round" stroke-miterlimit="10" d="M1.5,3.1c0,0,200,4,-270.5,64.5s250.5+10.5,-100,170"/>
      
      <path class="dashed" fill="none" stroke="white" stroke-width="8" stroke-linejoin="round" stroke-miterlimit="10" d="M1.5,3.1c0,0,200,4,-270.5,64.5s250.5+10.5,-100,170"/>   
            
            <polyline id="arrow2" points="0,-9 18,0 0,9 5,0" fill="#db5862">
              <animateMotion rotate="auto" begin="1s" dur="1.6s" repeatCount="1" fill="freeze">
                <mpath xlink:href="#Path-2" />
              </animateMotion>
            </polyline>
      
          </g>
        </svg>
      </div>
    </div>
    <div class="col-8" >
      
    
       
      </div>
     
    </div>
    <div class="row">
      <div class="col-4" >
       
    </div>
    <div class="col-8" id="info">
      
      <div class="blog-slider">
        <div class="blog-slider__wrp swiper-wrapper">
          <div class="blog-slider__item swiper-slide">
            <div class="blog-slider__img ">
              <video autoplay loop muted playsinline class="item-background">
                <source src="assets/tacotron.mp4" type="video/mp4">
            </video>
              
            </div>
            <div class="blog-slider__content">
              <span class="blog-slider__code">TTS</span>
              <div class="blog-slider__title">Tacotron 2 and WaveGlow model</div>
              <div class="blog-slider__text">The Tacotron 2 and WaveGlow model form a text-to-speech system that enables user to synthesise a natural sounding speech from raw transcripts without any additional prosody information. The Tacotron 2 model produces mel spectrograms from input text using encoder-decoder architecture. WaveGlow is a flow-based model that consumes the mel spectrograms to generate speech. </div>
              <a href="https://pytorch.org/hub/nvidia_deeplearningexamples_tacotron2/#:~:text=The%20Tacotron%202%20and%20WaveGlow,text%20using%20encoder%2Ddecoder%20architecture." class="blog-slider__button">READ MORE</a>
            </div>
          </div>          
          
         
          
        </div>
       
      </div>
       
      </div>
     
    </div>
  </div>


     <div >
<p id="space"></p>
     </div>
   
  


  <!--  <div class="container">
        <div id="slide">
            <div class="item" style="background-clip: url();">
                <video autoplay loop muted playsinline class="item-background">
                    <source src="assets/tacotron.mp4" type="video/mp4">
                </video>
                <div class="content">
                    <div class="name">Tacotron 2 and WaveGlow model</div>
                    <div class="des">The Tacotron 2 and WaveGlow model form a text-to-speech system that enables user to synthesise a natural sounding speech from raw transcripts without any additional prosody information. The Tacotron 2 model produces mel spectrograms from input text using encoder-decoder architecture. WaveGlow is a flow-based model that consumes the mel spectrograms to generate speech.</div>
                    <a href="https://pytorch.org/hub/nvidia_deeplearningexamples_tacotron2/#:~:text=The%20Tacotron%202%20and%20WaveGlow,text%20using%20encoder%2Ddecoder%20architecture." target="_blank"><button>See more</button></a>
                </div>
            </div>
            <div class="item" style="background-image: url(assets/img3.jpg);">
                <div class="content">
                    <div class="name">SignVani</div>
                    <div class="des">SignVani is an innovative project that aims to bridge the communication gap between sign language users and non-sign language speakers. Using advanced computer vision techniques, it detects and translates sign language gestures into English text, allowing seamless communication. Additionally, SignVani goes a step further by translating the English text into Konkani and utilizing text-to-speech technology to deliver spoken translations in the Konkani language, making it accessible to goan audience and promoting inclusivity.</div>                    
                </div>
            </div>
            <div class="item" style="background-image: url(assets/model.gif);">
                <div class="content">
                    <div class="name">Models Used to build SignVani Project</div>                    
                </div>
            </div>
            <div class="item" style="background-image: url(assets/lstm.gif);">
                <div class="content">
                    <div class="name">LSTM</div>
                    <div class="des">LSTM networks are recurrent neural networks that may learn order dependence in sequence prediction challengesThe LSTM (Long Short-Term Memory) model is a powerful neural network architecture commonly used for sign language detection. By leveraging its ability to capture long-range dependencies and handle sequential data, the LSTM model demonstrates promising accuracy in recognizing and interpreting sign language gestures, facilitating effective communication for the deaf and hard of hearing.</div>
                    <a href="https://medium.com/@mayank.bali/sign-language-detection-for-deaf-using-deep-learning-mediapipe-u-opencv-4c5151e2374c" target="_blank"><button>See more</button></a>
                </div>
            </div>
            <div class="item" style="background-image: url(assets/encoderdecoder.gif);">
                <div class="content">
                    <div class="name">Seq2Seq-LSTM-Model</div>
                    <div class="des">The Seq2Seq-LSTM model is a sophisticated deep learning architecture that excels in English to Konkani text translation. By employing a sequence-to-sequence framework with LSTM layers, it captures the contextual information and linguistic patterns to generate accurate and meaningful translations, bridging the language barrier between English and Konkani with impressive fluency and precision.</div>
                    <a href="https://www.codingninjas.com/codestudio/library/encoder-decoder-models" target="_blank"><button>See more</button></a>
                </div>
            </div>
           
         </div>
        <div class="buttons">
            <button id="prev"><i class="fa-solid fa-angle-left"></i></button>
            <button id="next"><i class="fa-solid fa-angle-right"></i></button>
        </div>
    </div>-->

    
</body>
</html>
  